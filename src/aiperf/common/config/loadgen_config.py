# SPDX-FileCopyrightText: Copyright (c) 2025-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

from typing import Annotated

from cyclopts import Parameter
from pydantic import Field, model_validator

from aiperf.common.config.base_config import BaseConfig
from aiperf.common.config.cli_parameter import CLIParameter
from aiperf.common.config.config_defaults import LoadGeneratorDefaults
from aiperf.common.config.groups import Groups
from aiperf.plugin.enums import ArrivalPattern


class LoadGeneratorConfig(BaseConfig):
    """A configuration class for defining top-level load generator settings."""

    _CLI_GROUP = Groups.LOAD_GENERATOR

    benchmark_duration: Annotated[
        float | None,
        Field(
            gt=0,
            description="Maximum benchmark runtime in seconds. When set, AIPerf stops issuing new requests after this duration, "
            "Responses received within `--benchmark-grace-period` after duration ends are included in metrics.",
        ),
        CLIParameter(
            name=("--benchmark-duration",),
            group=_CLI_GROUP,
        ),
    ] = None

    benchmark_grace_period: Annotated[
        float,
        Field(
            ge=0,
            description="The grace period in seconds to wait for responses after benchmark duration ends. "
            "Only applies when --benchmark-duration is set. Responses received within this period "
            "are included in metrics. Use 'inf' to wait indefinitely for all responses.",
        ),
        CLIParameter(
            name=("--benchmark-grace-period",),
            group=_CLI_GROUP,
        ),
    ] = LoadGeneratorDefaults.BENCHMARK_GRACE_PERIOD

    concurrency: Annotated[
        int | None,
        Field(
            ge=1,
            description="Number of concurrent requests to maintain. AIPerf issues a new request immediately when one completes, "
            "maintaining this level of in-flight requests. Can be combined with `--request-rate` to control the request rate.",
        ),
        CLIParameter(
            name=(
                "--concurrency",  # GenAI-Perf
            ),
            group=_CLI_GROUP,
        ),
    ] = None

    prefill_concurrency: Annotated[
        int | None,
        Field(
            ge=1,
            description="Max concurrent requests waiting for first token (prefill phase). "
            "Limits how many requests can be in the prefill/prompt-processing stage simultaneously.",
        ),
        CLIParameter(
            name=("--prefill-concurrency",),
            group=_CLI_GROUP,
        ),
    ] = None

    request_rate: Annotated[
        float | None,
        Field(
            gt=0,
            description="Target request rate in requests per second. AIPerf generates request timing according to `--request-rate-mode` "
            "to achieve this average rate. Can be combined with `--concurrency` to control the number of concurrent requests. "
            "Supports fractional rates (e.g., `0.5` = 1 request every 2 seconds).",
        ),
        CLIParameter(
            name=(
                "--request-rate",  # GenAI-Perf
            ),
            group=_CLI_GROUP,
        ),
    ] = None

    arrival_pattern: Annotated[
        ArrivalPattern,
        Field(
            description="Sets the arrival pattern for the load generated by AIPerf. Valid values: constant, poisson, gamma.\n"
            "`constant`: Generate requests at a fixed rate.\n"
            "`poisson`: Generate requests using a poisson distribution.\n"
            "`gamma`: Generate requests using a gamma distribution with tunable smoothness."
        ),
        CLIParameter(
            name=("--arrival-pattern", "--request-rate-mode"),
            group=_CLI_GROUP,
        ),
    ] = LoadGeneratorDefaults.ARRIVAL_PATTERN

    arrival_smoothness: Annotated[
        float | None,
        Field(
            gt=0,
            description="Smoothness parameter for gamma distribution arrivals (--arrival-pattern gamma). "
            "Controls the shape of the arrival pattern:\n"
            "- 1.0: Poisson-like (exponential inter-arrivals, default)\n"
            "- <1.0: Bursty/clustered arrivals (higher variance)\n"
            "- >1.0: Smooth/regular arrivals (lower variance)\n"
            "Compatible with vLLM's --burstiness parameter (same value = same distribution).",
        ),
        CLIParameter(
            name=("--arrival-smoothness", "--vllm-burstiness"),
            group=_CLI_GROUP,
        ),
    ] = None

    request_count: Annotated[
        int | None,
        Field(
            ge=1,
            description="The maximum number of requests to send. If not set, will be automatically determined based "
            "on the timing mode and dataset size. For synthetic datasets, this will be `max(10, concurrency * 2)`.",
        ),
        CLIParameter(
            name=(
                "--request-count",  # GenAI-Perf
                "--num-requests",  # GenAI-Perf
            ),
            group=_CLI_GROUP,
        ),
    ] = None

    warmup_request_count: Annotated[
        int | None,
        Field(
            gt=0,
            description="The maximum number of warmup requests to send before benchmarking. "
            "If not set and no --warmup-duration is set, then no warmup phase will be used.",
        ),
        CLIParameter(
            name=(
                "--warmup-request-count",  # GenAI-Perf
                "--num-warmup-requests",  # GenAI-Perf
            ),
            group=_CLI_GROUP,
        ),
    ] = None

    warmup_duration: Annotated[
        float | None,
        Field(
            gt=0,
            description="The maximum duration in seconds for the warmup phase. If not set, it will use the `--warmup-request-count` value. "
            "If neither are set, no warmup phase will be used.",
        ),
        CLIParameter(
            name=("--warmup-duration",),
            group=_CLI_GROUP,
        ),
    ] = None

    warmup_num_sessions: Annotated[
        int | None,
        Field(
            ge=1,
            description="The number of sessions to use for the warmup phase. If not set, it will use the `--warmup-request-count` value.",
        ),
        CLIParameter(
            name=("--num-warmup-sessions",),
            group=_CLI_GROUP,
        ),
    ] = None

    warmup_concurrency: Annotated[
        int | None,
        Field(
            ge=1,
            description="The concurrency value to use for the warmup phase. If not set, it will use the `--concurrency` value.",
        ),
        CLIParameter(
            name=("--warmup-concurrency",),
            group=_CLI_GROUP,
        ),
    ] = None

    warmup_prefill_concurrency: Annotated[
        int | None,
        Field(
            ge=1,
            description="The prefill concurrency value to use for the warmup phase. "
            "If not set, it will use the `--prefill-concurrency` value.",
        ),
        CLIParameter(
            name=("--warmup-prefill-concurrency",),
            group=_CLI_GROUP,
        ),
    ] = None

    warmup_request_rate: Annotated[
        float | None,
        Field(
            gt=0,
            description="The request rate to use for the warmup phase. If not set, it will use the `--request-rate` value.",
        ),
        CLIParameter(
            name=("--warmup-request-rate",),
            group=_CLI_GROUP,
        ),
    ] = None

    warmup_arrival_pattern: Annotated[
        ArrivalPattern | None,
        Field(
            default=None,
            description="The arrival pattern to use for the warmup phase. "
            "If not set, it will use the `--arrival-pattern` value. "
            "Valid values: constant, poisson, gamma.",
        ),
        CLIParameter(
            name=("--warmup-arrival-pattern",),
            group=_CLI_GROUP,
            show_choices=False,
        ),
    ] = None

    warmup_grace_period: Annotated[
        float | None,
        Field(
            ge=0,
            description="The grace period in seconds to wait for responses after warmup phase ends. "
            "Only applies when warmup is enabled. Responses received within this period "
            "are included in warmup completion. If not set, waits indefinitely for all warmup responses.",
        ),
        CLIParameter(
            name=("--warmup-grace-period",),
            group=_CLI_GROUP,
        ),
    ] = None

    # TODO: We should add a warning for values below 1.0, to ensure the user is aware that the value is a percentage.
    request_cancellation_rate: Annotated[
        float | None,
        Field(
            gt=0.0,
            le=100.0,
            description="Percentage (0-100) of requests to cancel for testing cancellation handling. Cancelled requests are sent normally "
            "but aborted after `--request-cancellation-delay` seconds. Useful for testing graceful degradation and resource cleanup.",
        ),
        CLIParameter(
            name=("--request-cancellation-rate",),
            group=_CLI_GROUP,
        ),
    ] = None

    request_cancellation_delay: Annotated[
        float,
        Field(
            ge=0.0,
            description="Seconds to wait after the request is fully sent before cancelling. "
            "A delay of 0 means 'send the full request, then immediately disconnect'. "
            "Requires --request-cancellation-rate to be set.",
        ),
        CLIParameter(
            name=("--request-cancellation-delay",),
            group=_CLI_GROUP,
        ),
    ] = 0.0

    user_centric_rate: Annotated[
        float | None,
        Field(
            gt=0,
            description="Enable user-centric rate limiting mode with the specified request rate (QPS). "
            "Each user has a gap = num_users / qps between turns. "
            "Users block on their previous turn (no interleaving within a user). "
            "New users are spawned on a fixed schedule to maintain steady-state throughput. "
            "Designed for KV cache benchmarking with realistic multi-user patterns. "
            "Requires --num-users to be set.",
        ),
        CLIParameter(
            name=("--user-centric-rate",),
            group=_CLI_GROUP,
        ),
    ] = None

    num_users: Annotated[
        int | None,
        Field(
            ge=1,
            description="The number of initial users to use for --user-centric-rate mode.",
        ),
        CLIParameter(
            name=("--num-users",),
            group=_CLI_GROUP,
        ),
    ] = None

    concurrency_ramp_duration: Annotated[
        float | None,
        Field(
            gt=0,
            description="Duration in seconds to ramp session concurrency from 1 to target. "
            "Useful for gradual warm-up of the target system.",
        ),
        CLIParameter(
            name=("--concurrency-ramp-duration",),
            group=_CLI_GROUP,
        ),
    ] = None

    prefill_concurrency_ramp_duration: Annotated[
        float | None,
        Field(
            gt=0,
            description="Duration in seconds to ramp prefill concurrency from 1 to target.",
        ),
        CLIParameter(
            name=("--prefill-concurrency-ramp-duration",),
            group=_CLI_GROUP,
        ),
    ] = None

    warmup_concurrency_ramp_duration: Annotated[
        float | None,
        Field(
            gt=0,
            description="Duration in seconds to ramp warmup session concurrency from 1 to target. "
            "If not set, uses `--concurrency-ramp-duration` value.",
        ),
        CLIParameter(
            name=("--warmup-concurrency-ramp-duration",),
            group=_CLI_GROUP,
        ),
    ] = None

    warmup_prefill_concurrency_ramp_duration: Annotated[
        float | None,
        Field(
            gt=0,
            description="Duration in seconds to ramp warmup prefill concurrency from 1 to target. "
            "If not set, uses `--prefill-concurrency-ramp-duration` value.",
        ),
        CLIParameter(
            name=("--warmup-prefill-concurrency-ramp-duration",),
            group=_CLI_GROUP,
        ),
    ] = None

    request_rate_ramp_duration: Annotated[
        float | None,
        Field(
            gt=0,
            description="Duration in seconds to ramp request rate from a proportional minimum to target. "
            "Start rate is calculated as target * (update_interval / duration), ensuring correct "
            "behavior for target rates below 1 QPS. Useful for gradual warm-up of the target system.",
        ),
        CLIParameter(
            name=("--request-rate-ramp-duration",),
            group=_CLI_GROUP,
        ),
    ] = None

    warmup_request_rate_ramp_duration: Annotated[
        float | None,
        Field(
            gt=0,
            description="Duration in seconds to ramp warmup request rate from a proportional minimum to target. "
            "Start rate is calculated as target * (update_interval / duration). "
            "If not set, uses `--request-rate-ramp-duration` value.",
        ),
        CLIParameter(
            name=("--warmup-request-rate-ramp-duration",),
            group=_CLI_GROUP,
        ),
    ] = None

    # Upper limit of 10 runs balances statistical validity with practical considerations:
    # - Statistical: 10 samples provide reasonable confidence intervals (t-distribution)
    # - Practical: Limits total benchmark time (10 runs can take hours for long benchmarks)
    # - Diminishing returns: Confidence interval width decreases with sqrt(n), so gains
    #   beyond 10 runs are marginal compared to the additional time investment
    # - Resource efficiency: Reduces compute/GPU costs while maintaining statistical rigor
    num_profile_runs: Annotated[
        int,
        Field(
            ge=1,
            le=10,
            description="Number of profile runs to execute for confidence reporting. "
            "Must be between 1 and 10. "
            "When set to 1 (default), runs a single benchmark. "
            "When set to >1, runs multiple benchmarks and computes aggregate statistics "
            "(mean, std, confidence intervals, coefficient of variation) across runs. "
            "Useful for quantifying variance and establishing confidence in results.",
        ),
        CLIParameter(
            name=("--num-profile-runs",),
            group=Groups.MULTI_RUN,
        ),
    ] = 1
    profile_run_cooldown_seconds: Annotated[
        float,
        Field(
            ge=0,
            description="Cooldown duration in seconds between profile runs. "
            "Only applies when --num-profile-runs > 1. "
            "Allows the system to stabilize between runs (e.g., clear caches, cool down GPUs). "
            "Default is 0 (no cooldown).",
        ),
        CLIParameter(
            name=("--profile-run-cooldown-seconds",),
            group=Groups.MULTI_RUN,
        ),
    ] = 0.0

    confidence_level: Annotated[
        float,
        Field(
            gt=0,
            lt=1,
            description="Confidence level for computing confidence intervals (0-1). "
            "Only applies when --num-profile-runs > 1. "
            "Common values: 0.90 (90%), 0.95 (95%, default), 0.99 (99%). "
            "Higher values produce wider confidence intervals.",
        ),
        CLIParameter(
            name=("--confidence-level",),
            group=Groups.MULTI_RUN,
        ),
    ] = 0.95

    profile_run_disable_warmup_after_first: Annotated[
        bool,
        Field(
            description="Disable warmup for profile runs after the first. "
            "Only applies when --num-profile-runs > 1. "
            "When True (default), only the first run includes warmup, subsequent runs "
            "measure steady-state performance for more accurate aggregate statistics. "
            "When False, all runs include warmup (useful for long cooldown periods "
            "or when testing cold-start performance).",
        ),
        Parameter(
            name=("--profile-run-disable-warmup-after-first",),
            group=Groups.MULTI_RUN,
            show_env_var=False,
            negative="--no-profile-run-disable-warmup-after-first",
        ),
    ] = True

    set_consistent_seed: Annotated[
        bool,
        Field(
            description="Automatically set random seed for consistent workloads across runs. "
            "Only applies when --num-profile-runs > 1. "
            "When True (default), automatically sets --random-seed=42 if not specified, "
            "ensuring identical workloads across all runs for valid statistical comparison. "
            "When False, preserves None seed, resulting in different workloads per run "
            "(not recommended for confidence reporting as it produces invalid statistics). "
            "If --random-seed is explicitly set, that value is always used regardless of this setting.",
        ),
        Parameter(
            name=("--set-consistent-seed",),
            group=Groups.MULTI_RUN,
            show_env_var=False,
            negative="--no-set-consistent-seed",
        ),
    ] = True

    def disable_warmup(self) -> None:
        """Disable all warmup-related parameters.

        This method explicitly sets all warmup fields to None, ensuring
        that no warmup phase runs. This is the authoritative list of
        warmup fields - if a new warmup field is added, it MUST be
        added to this method.

        This design makes it explicit which fields are warmup-related
        and ensures the list is maintained in one place (the config class).
        """
        # Core warmup parameters
        self.warmup_request_count = None
        self.warmup_duration = None
        self.warmup_num_sessions = None

        # Warmup load parameters
        self.warmup_concurrency = None
        self.warmup_prefill_concurrency = None
        self.warmup_request_rate = None
        self.warmup_arrival_pattern = None

        # Warmup timing parameters
        self.warmup_grace_period = None

        # Warmup ramp parameters
        self.warmup_concurrency_ramp_duration = None
        self.warmup_prefill_concurrency_ramp_duration = None
        self.warmup_request_rate_ramp_duration = None

    @model_validator(mode="after")
    def validate_multi_run_params(self) -> "LoadGeneratorConfig":
        """Validate that multi-run specific parameters are only set when num_profile_runs > 1.

        Raises:
            ValueError: If confidence_level, profile_run_disable_warmup_after_first,
                       profile_run_cooldown_seconds, or set_consistent_seed are explicitly
                       set when num_profile_runs == 1.
        """
        if self.num_profile_runs == 1:
            # Check if confidence_level was explicitly set by the user
            if "confidence_level" in self.model_fields_set:
                raise ValueError(
                    "--confidence-level only applies when --num-profile-runs > 1. "
                    "Remove --confidence-level or increase --num-profile-runs."
                )

            # Check if profile_run_disable_warmup_after_first was explicitly set by the user
            if "profile_run_disable_warmup_after_first" in self.model_fields_set:
                raise ValueError(
                    "--profile-run-disable-warmup-after-first only applies when --num-profile-runs > 1. "
                    "Remove --profile-run-disable-warmup-after-first or increase --num-profile-runs."
                )

            # Check if profile_run_cooldown_seconds was explicitly set by the user
            if "profile_run_cooldown_seconds" in self.model_fields_set:
                raise ValueError(
                    "--profile-run-cooldown-seconds only applies when --num-profile-runs > 1. "
                    "Remove --profile-run-cooldown-seconds or increase --num-profile-runs."
                )

            # Check if set_consistent_seed was explicitly set by the user
            if "set_consistent_seed" in self.model_fields_set:
                raise ValueError(
                    "--set-consistent-seed only applies when --num-profile-runs > 1. "
                    "Remove --set-consistent-seed or increase --num-profile-runs."
                )

        return self
